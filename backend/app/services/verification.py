"""Chain-of-Verification (CoVe) service for reducing AI hallucinations.

This service implements the CoVe approach:
1. Generate baseline response
2. Extract factual claims from response
3. Verify claims against search results
4. Generate corrected response if needed

Reference: https://arxiv.org/abs/2309.11495
"""

import json
import logging
from typing import Any

from openai import OpenAI

from app.core.config import get_settings

logger = logging.getLogger(__name__)

# Prompt for extracting factual claims
EXTRACT_CLAIMS_PROMPT = """è¯·ä»Žä»¥ä¸‹å›žå¤ä¸­æå–æ‰€æœ‰äº‹å®žæ€§é™ˆè¿°ï¼ˆä¸åŒ…æ‹¬æƒ…æ„Ÿè¡¨è¾¾å’Œå»ºè®®ï¼‰ã€‚

å›žå¤å†…å®¹ï¼š
{response}

è¯·ä»¥ JSON æ•°ç»„æ ¼å¼è¿”å›žï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªäº‹å®žæ€§é™ˆè¿°ã€‚ä¾‹å¦‚ï¼š
["äº§åŽæŠ‘éƒå½±å“10-15%çš„æ–°å¦ˆå¦ˆ", "ç›†åº•è‚Œä¿®å¤éœ€è¦6-8å‘¨"]

å¦‚æžœæ²¡æœ‰äº‹å®žæ€§é™ˆè¿°ï¼Œè¿”å›žç©ºæ•°ç»„ []ã€‚
åªè¿”å›ž JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""

# Prompt for verifying claims
VERIFY_CLAIMS_PROMPT = """è¯·éªŒè¯ä»¥ä¸‹äº‹å®žæ€§é™ˆè¿°æ˜¯å¦ä¸Žå‚è€ƒèµ„æ–™ä¸€è‡´ã€‚

## äº‹å®žæ€§é™ˆè¿°
{claims}

## å‚è€ƒèµ„æ–™
{context}

è¯·ä»¥ JSON æ ¼å¼è¿”å›žéªŒè¯ç»“æžœï¼š
{{
  "verified": ["å·²éªŒè¯çš„é™ˆè¿°1", "å·²éªŒè¯çš„é™ˆè¿°2"],
  "unverified": ["æ— æ³•éªŒè¯çš„é™ˆè¿°1"],
  "incorrect": ["ä¸Žå‚è€ƒèµ„æ–™çŸ›ç›¾çš„é™ˆè¿°1"]
}}

åªè¿”å›ž JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""

# Prompt for generating corrected response
CORRECT_RESPONSE_PROMPT = """è¯·ä¿®æ­£ä»¥ä¸‹å›žå¤ï¼Œç¡®ä¿äº‹å®žå‡†ç¡®ã€‚

## åŽŸå§‹å›žå¤
{response}

## éªŒè¯ç»“æžœ
- å·²éªŒè¯çš„äº‹å®žï¼š{verified}
- æ— æ³•éªŒè¯çš„äº‹å®žï¼š{unverified}
- é”™è¯¯çš„äº‹å®žï¼š{incorrect}

## å‚è€ƒèµ„æ–™
{context}

## ä¿®æ­£è¦æ±‚
1. ä¿ç•™å·²éªŒè¯çš„äº‹å®ž
2. å¯¹æ— æ³•éªŒè¯çš„äº‹å®žï¼Œæ”¹ä¸ºæ›´è°¨æ…Žçš„è¡¨è¿°ï¼ˆå¦‚"æ®äº†è§£"ã€"ä¸€èˆ¬è®¤ä¸º"ï¼‰
3. åˆ é™¤æˆ–æ›´æ­£é”™è¯¯çš„äº‹å®ž
4. ä¿æŒåŽŸæœ‰çš„æ¸©æš–ã€æœ‰åŒç†å¿ƒçš„è¯­æ°”
5. å›žå¤é•¿åº¦æŽ§åˆ¶åœ¨ 100-200 å­—

è¯·ç›´æŽ¥è¾“å‡ºä¿®æ­£åŽçš„å›žå¤ï¼Œä¸éœ€è¦ä»»ä½•å‰ç¼€ã€‚"""


class ChainOfVerification:
    """Chain-of-Verification service for fact-checking LLM responses."""

    def __init__(self) -> None:
        settings = get_settings()
        self._api_key = settings.modelscope_key
        self._base_url = settings.modelscope_base_url
        self._model = settings.modelscope_model
        self._client: OpenAI | None = None

    @property
    def client(self) -> OpenAI:
        """Lazy load OpenAI client."""
        if self._client is None:
            if not self._api_key:
                raise ValueError("MODELSCOPE_KEY not configured")
            self._client = OpenAI(
                api_key=self._api_key,
                base_url=self._base_url,
            )
        return self._client

    def _extract_claims(self, response: str) -> list[str]:
        """Extract factual claims from a response."""
        try:
            result = self.client.chat.completions.create(
                model=self._model,
                messages=[
                    {
                        "role": "user",
                        "content": EXTRACT_CLAIMS_PROMPT.format(response=response),
                    }
                ],
                temperature=0.1,
                max_tokens=512,
            )
            content = result.choices[0].message.content or "[]"
            # Parse JSON
            claims = json.loads(content.strip())
            if isinstance(claims, list):
                return claims
            return []
        except Exception as e:
            logger.warning(f"Failed to extract claims: {e}")
            return []

    def _verify_claims(self, claims: list[str], context: str) -> dict[str, list[str]]:
        """Verify claims against search context."""
        if not claims:
            return {"verified": [], "unverified": [], "incorrect": []}

        try:
            claims_text = "\n".join(f"- {c}" for c in claims)
            result = self.client.chat.completions.create(
                model=self._model,
                messages=[
                    {
                        "role": "user",
                        "content": VERIFY_CLAIMS_PROMPT.format(
                            claims=claims_text, context=context
                        ),
                    }
                ],
                temperature=0.1,
                max_tokens=512,
            )
            content = result.choices[0].message.content or "{}"
            verification = json.loads(content.strip())
            return {
                "verified": verification.get("verified", []),
                "unverified": verification.get("unverified", []),
                "incorrect": verification.get("incorrect", []),
            }
        except Exception as e:
            logger.warning(f"Failed to verify claims: {e}")
            # If verification fails, treat all as unverified
            return {"verified": [], "unverified": claims, "incorrect": []}

    def _correct_response(
        self,
        response: str,
        verification: dict[str, list[str]],
        context: str,
    ) -> str:
        """Generate corrected response based on verification."""
        try:
            result = self.client.chat.completions.create(
                model=self._model,
                messages=[
                    {
                        "role": "user",
                        "content": CORRECT_RESPONSE_PROMPT.format(
                            response=response,
                            verified=", ".join(verification["verified"]) or "æ— ",
                            unverified=", ".join(verification["unverified"]) or "æ— ",
                            incorrect=", ".join(verification["incorrect"]) or "æ— ",
                            context=context,
                        ),
                    }
                ],
                temperature=0.7,
                max_tokens=512,
            )
            return result.choices[0].message.content or response
        except Exception as e:
            logger.warning(f"Failed to correct response: {e}")
            return response

    def verify_and_correct(
        self,
        response: str,
        search_context: str | None,
    ) -> tuple[str, dict[str, Any]]:
        """
        Verify a response and correct if needed.

        Args:
            response: The initial LLM response
            search_context: The web search context used for generation

        Returns:
            Tuple of (corrected_response, verification_metadata)
        """
        # If no search context, skip verification
        if not search_context:
            return response, {"skipped": True, "reason": "no_search_context"}

        # Step 1: Extract factual claims
        claims = self._extract_claims(response)
        logger.info(f"Extracted {len(claims)} claims from response")

        if not claims:
            return response, {"skipped": True, "reason": "no_claims"}

        # Step 2: Verify claims against context
        verification = self._verify_claims(claims, search_context)
        logger.info(
            f"Verification: {len(verification['verified'])} verified, "
            f"{len(verification['unverified'])} unverified, "
            f"{len(verification['incorrect'])} incorrect"
        )

        # Step 3: If there are incorrect claims, correct the response
        if verification["incorrect"]:
            corrected = self._correct_response(response, verification, search_context)
            return corrected, {
                "corrected": True,
                "claims": claims,
                "verification": verification,
            }

        # If only unverified claims, add disclaimer but don't rewrite
        if verification["unverified"] and not verification["verified"]:
            # Add a gentle disclaimer
            disclaimer = "\n\nï¼ˆä»¥ä¸Šä¿¡æ¯ä»…ä¾›å‚è€ƒï¼Œå»ºè®®å’¨è¯¢ä¸“ä¸šåŒ»ç”ŸèŽ·å–å‡†ç¡®å»ºè®® ðŸ’—ï¼‰"
            return response + disclaimer, {
                "disclaimer_added": True,
                "claims": claims,
                "verification": verification,
            }

        return response, {
            "verified": True,
            "claims": claims,
            "verification": verification,
        }


# Global service instance
_cove_service: ChainOfVerification | None = None


def get_cove_service() -> ChainOfVerification:
    """Get the Chain-of-Verification service singleton."""
    global _cove_service
    if _cove_service is None:
        _cove_service = ChainOfVerification()
    return _cove_service
